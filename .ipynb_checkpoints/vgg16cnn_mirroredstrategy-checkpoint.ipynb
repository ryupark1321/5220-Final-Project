{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64f72e7c-de07-48c5-b906-2cf4a73d5feb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten, Dense, Conv2D, Rescaling\n",
    "import os\n",
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85818565-3c93-4135-bda6-b9475c25c2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052073b-07ae-4572-9456-3d6e9bf318d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data and distribute it\n",
    "\n",
    "batch_size = 128\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "scratch = os.environ['SCRATCH']\n",
    "train_dir = os.path.join(scratch,'imagenette/imagenette2/train/')\n",
    "val_dir = os.path.join(scratch,'imagenette/imagenette2/val/')\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# with strategy.scope():\n",
    "  # Create the layer(s) under scope.\n",
    "\n",
    "def dataset_fn(input_context):\n",
    "  # a tf.data.Dataset\n",
    "  dataset = train_dataset.repeat()\n",
    "\n",
    "  # Custom your batching, sharding, prefetching, etc.\n",
    "  global_batch_size = 128\n",
    "  batch_size = input_context.get_per_replica_batch_size(global_batch_size)\n",
    "  dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "  dataset = dataset.shard(\n",
    "      input_context.num_input_pipelines,\n",
    "      input_context.input_pipeline_id\n",
    "  )\n",
    "  return dataset\n",
    "with strategy.scope():\n",
    "    distributed_dataset = strategy.distribute_datasets_from_function(dataset_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977d5fac-3930-4393-9779-9f08dd82a5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_dataset.take(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df80ecd-415c-47c6-abc3-66486308ff1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "\n",
    "def vgg16():\n",
    "    model = Sequential([\n",
    "        Rescaling(1./255),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3), strides=1),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        Conv2D(512, (3, 3), activation='relu', padding='same', strides=1),\n",
    "        MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dense(1000, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c98ce9-72f1-4827-803b-70a4d7504560",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a checkpoint directory to store the checkpoints.\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c99e43-675f-44b9-83d3-05d2aaa83263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  # Set reduction to `NONE` so you can do the reduction yourself.\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True,\n",
    "      reduction=tf.keras.losses.Reduction.NONE)\n",
    "  def compute_loss(labels, predictions, model_losses):\n",
    "    per_example_loss = loss_object(labels, predictions)\n",
    "    loss = tf.nn.compute_average_loss(per_example_loss)\n",
    "    if model_losses:\n",
    "      loss += tf.nn.scale_regularization_loss(tf.add_n(model_losses))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058039a3-3361-4852-8e4b-26cc18dd6d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='train_accuracy')\n",
    "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "      name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2b1d123-5f84-479f-8ad9-ba9ee3488808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A model, an optimizer, and a checkpoint must be created under `strategy.scope`.\n",
    "with strategy.scope():\n",
    "  model = vgg16()\n",
    "\n",
    "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51f62ca2-6438-4b8c-b4a2-900514208263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(inputs):\n",
    "  images, labels = inputs\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(images, training=True)\n",
    "    loss = compute_loss(labels, predictions, model.losses)\n",
    "\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_accuracy.update_state(labels, predictions)\n",
    "  return loss\n",
    "\n",
    "def test_step(inputs):\n",
    "  images, labels = inputs\n",
    "\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss.update_state(t_loss)\n",
    "  test_accuracy.update_state(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920d74ff-7911-41c1-a563-a5bf7f1b087d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b12c25f-2c82-45e8-ab17-bfce1c0ffe5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot batch tensors with different shapes in component 0. First element had shape [128,224,224,3] and element 9 had shape [125,224,224,3].\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]] [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     16\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m distributed_dataset:\n\u001b[1;32m     18\u001b[0m   total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m distributed_train_step(x)\n\u001b[1;32m     19\u001b[0m   num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/distribute/input_lib.py:573\u001b[0m, in \u001b[0;36mDistributedIteratorBase.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/distribute/input_lib.py:630\u001b[0m, in \u001b[0;36mDistributedIteratorBase.get_next\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext(iterator) should be called from outside of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    626\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplica_fn. e.g. strategy.run(replica_fn, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    627\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs=(next(iterator),))\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_get_next_as_optional:\n\u001b[0;32m--> 630\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next_no_partial_batch_handling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m optional_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, worker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_workers\u001b[38;5;241m.\u001b[39mworker_devices):\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/distribute/input_lib.py:662\u001b[0m, in \u001b[0;36mDistributedIteratorBase._get_next_no_partial_batch_handling\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    659\u001b[0m     new_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    660\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(worker):\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;66;03m# Make `replicas` a flat list of values across all replicas.\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     replicas\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next_as_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_name\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _create_per_replica(replicas, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/distribute/input_lib.py:1632\u001b[0m, in \u001b[0;36m_SingleWorkerDatasetIteratorBase.get_next_as_list\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m name\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker):\n\u001b[0;32m-> 1632\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_data_list_with_options(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:531\u001b[0m, in \u001b[0;36mOwnedMultiDeviceIterator.get_next\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_devices):\n\u001b[1;32m    530\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(device):\n\u001b[0;32m--> 531\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device_iterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:819\u001b[0m, in \u001b[0;36mOwnedIterator.get_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_next\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 819\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/data/ops/iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[0;32m--> 749\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3017\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3015\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m   3016\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 3017\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3018\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[1;32m   3019\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/nersc/pm-2022q4/sw/tensorflow/2.9.0/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot batch tensors with different shapes in component 0. First element had shape [128,224,224,3] and element 9 had shape [125,224,224,3].\n\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n\t [[RemoteCall]] [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "# `run` replicates the provided computation and runs it\n",
    "# with the distributed input.\n",
    "@tf.function\n",
    "def distributed_train_step(dataset_inputs):\n",
    "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
    "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
    "                         axis=None)\n",
    "\n",
    "@tf.function\n",
    "def distributed_test_step(dataset_inputs):\n",
    "  return strategy.run(test_step, args=(dataset_inputs,))\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  # TRAIN LOOP\n",
    "  total_loss = 0.0\n",
    "  num_batches = 0\n",
    "  for x in distributed_dataset:\n",
    "    total_loss += distributed_train_step(x)\n",
    "    num_batches += 1\n",
    "  train_loss = total_loss / num_batches\n",
    "\n",
    "  # TEST LOOP\n",
    "  for x in test_dist_dataset:\n",
    "    distributed_test_step(x)\n",
    "\n",
    "  if epoch % 2 == 0:\n",
    "    checkpoint.save(checkpoint_prefix)\n",
    "\n",
    "  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
    "              \"Test Accuracy: {}\")\n",
    "  print(template.format(epoch + 1, train_loss,\n",
    "                         train_accuracy.result() * 100, test_loss.result(),\n",
    "                         test_accuracy.result() * 100))\n",
    "\n",
    "  test_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402518e-b879-421b-9854-bffb7348db7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15504a-5303-4cd0-97d4-4d516147a9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-2.9.0",
   "language": "python",
   "name": "tensorflow-2.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
